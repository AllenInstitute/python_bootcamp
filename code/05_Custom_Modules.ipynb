{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"support_files/images/cropped-SummerWorkshop_Header.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<center><h1>Custom Modules and Version Control</h1></center>\n",
    "\n",
    "<p>We have seen that new functionality in Python can be encapsulated as a <i>module</i>, and that we can import modules into our own code. In this section we will create a new Python module. \n",
    "\n",
    "- Important because encapsulating functions makes them <i>reusable</i>. We will use this mechanism to develop tools that we can share with each other during the course.\n",
    "\n",
    "- Jupyter is not (currently) a good tool for developing modules, so we will do most of our work with a text editor/CodeOcean. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Let's begin by making a simple module. For now, it will contain just one function we can use to downsample time-series data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the code we'd like to include in the module:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def downsample(data, n, axis=0):\n",
    "    \"\"\"Reduce the number of samples in an array by averaging together\n",
    "    n samples at a time.\n",
    "    \"\"\"\n",
    "    if n <= 1:\n",
    "        return data\n",
    "    new_len = data.shape[axis] // n\n",
    "    s = list(data.shape)\n",
    "    s[axis] = new_len\n",
    "    s.insert(axis+1, n)\n",
    "    sl = [slice(None)] * data.ndim\n",
    "    sl[axis] = slice(0, new_len*n)\n",
    "    d1 = data[tuple(sl)]\n",
    "    d1.shape = tuple(s)\n",
    "    d2 = d1.mean(axis+1)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Just so we understand what this function does, let's generate a noisy time-series signal and plot it:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t = np.linspace(0, 10, 10000)\n",
    "data = np.sin(t) + 5 * np.random.normal(size=len(t))\n",
    "plt.plot(t, data)\n",
    "plt.ylim(-20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "And this is what the same signal looks like after it has been downsampled. Note that the downsampled signal has many fewer samples, and the overall noise is much smaller.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_data = downsample(data, 200)\n",
    "plt.plot(t[::200], ds_data)\n",
    "plt.ylim(-20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Just to reiterate: We have created a useful function, and now we would like to encapsulate it into a module so that\n",
    "\n",
    "<ul>\n",
    "<li>We can re-use this function in many different places without copying it, and\n",
    "<li>We can share this function with other people.\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "Here's how to turn this code into a module:\n",
    "<ol>\n",
    "<li>Open a code editor and paste in the definition of `downsample()` given above, including the `import numpy` statement.\n",
    "<li>Save the file as `my_module.py` in the same location as this notebook.\n",
    "</ol>\n",
    "<br>\n",
    "You're done!<br>\n",
    "\n",
    "Now let's see if it works:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old downsample (so you can't cheat!)\n",
    "if 'downsample' in locals():\n",
    "    del downsample\n",
    "\n",
    "# Import the new definition of `downsample` from your module\n",
    "from my_module import downsample\n",
    "\n",
    "# If you get \"ImportError: No module named my_module\", then make sure\n",
    "# the .py file was saved in the same folder as this notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test again:\n",
    "ds_data = downsample(data, 200)\n",
    "plt.plot(t[::200], ds_data)\n",
    "plt.ylim(-20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Good so far, but there are some issues with this approach:\n",
    "\n",
    "<ul>\n",
    "<li>As our code becomes more complex, we will often want to organize it into multiple files and make them all appear as a single importable module.\n",
    "<li>If we distribute this code, we will at least want to include a README to explain what it's about, so I'd really like my module to live inside its own folder.\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "So now we are going to turn this module into a <i>package</i>, which is really just a collection of modules inside a folder, along with some Python glue.\n",
    "<ol>\n",
    "<li>Make a new folder, in the same location as this notebook, called `my_package`\n",
    "<li>Move `my_module.py` into this new folder\n",
    "<li>Create an empty text file called `__init__.py` inside `my_package`. (note the double underscores)\n",
    "</ol>\n",
    "<br>\n",
    "The `__init__.py` file is a hint to Python that tells it \"this folder is a package that can be imported\".\n",
    "\n",
    "<hr>\n",
    "Now let's try importing from the new package:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old downsample (so you can't cheat!)\n",
    "if 'downsample' in locals():\n",
    "    del downsample\n",
    "\n",
    "# Import downsample from our shiny new package\n",
    "from my_package.my_module import downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test again:\n",
    "ds_data = downsample(data, 200)\n",
    "plt.plot(t[::200], ds_data)\n",
    "plt.ylim(-20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Now that we have a package and are able to import from it, let's re-name our module to be a little more informative and  build out our package!\n",
    "<ul>\n",
    "<li>Rename `my_module.py` to `data_processing.py`\n",
    "<li> Discuss the following methods -- which one should be in our current existing module, and which one should go in a new module? \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the methods we'd like to include in the package\n",
    "\n",
    "# which one should we put in data_processing.py, and which belongs in its own module?\n",
    "import numpy as np\n",
    "\n",
    "def normalize(data, axis=0):\n",
    "    \"\"\"Normalize an array along a given axis to have a mean of 0 and standard deviation of 1.\"\"\"\n",
    "    mean = np.mean(data, axis=axis, keepdims=True)\n",
    "    std = np.std(data, axis=axis, keepdims=True)\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "def detect_peaks(data, threshold, distance=1):\n",
    "    \"\"\"Detect peaks in a 1D array based on a threshold and minimum distance \n",
    "    between peaks.\n",
    "    \n",
    "    Parameters:\n",
    "    data : array-like\n",
    "        1D array of data to search for peaks.\n",
    "    threshold : float\n",
    "        Minimum value for a peak to be considered.\n",
    "    distance : int, optional\n",
    "        Minimum number of samples between consecutive peaks (default is 1).\n",
    "    \n",
    "    Returns:\n",
    "    array-like\n",
    "        Indices of the detected peaks.\n",
    "    \"\"\"\n",
    "    peaks = np.where((data[1:-1] > data[:-2]) & (data[1:-1] > data[2:]) & (data[1:-1] > threshold))[0] + 1\n",
    "    if distance > 1:\n",
    "        filtered_peaks = []\n",
    "        last_peak = -distance\n",
    "        for peak in peaks:\n",
    "            if peak - last_peak >= distance:\n",
    "                filtered_peaks.append(peak)\n",
    "                last_peak = peak\n",
    "        peaks = np.array(filtered_peaks)\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "Hopefully we all came to the conclusion that `normalize` can be packaged with `downsample`, while `detect_peaks` belongs in its own module. \n",
    "<ul>\n",
    "<li>Similar Purpose: downsample and normalize are both data preparation methods, often used sequentially to transform raw data, so they naturally belong together in the same module.\n",
    "\n",
    "<li>Different Functionality: detect_peaks serves a distinct purpose—identifying specific features (peaks) in data, which is more specialized and separate from general data transformation tasks.\n",
    "\n",
    "<li>Separation of Concerns: Grouping downsample and normalize together enhances cohesion, while placing detect_peaks in a separate module maintains modularity, making your package easier to navigate and use.\n",
    "</ul>\n",
    "\n",
    "Let's name the new module `peak_detection.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data_processing import downsample, normalize\n",
    "from signal_detection import detect_peaks\n",
    "\n",
    "# Generating the time vector and data\n",
    "t = np.linspace(0, 10, 10000)\n",
    "data = np.sin(t) + 5 * np.random.normal(size=len(t))\n",
    "\n",
    "# Downsample and normalize the data\n",
    "ds_data = downsample(data, 200)\n",
    "norm_data = normalize(ds_data)\n",
    "\n",
    "# Detect peaks in the normalized data\n",
    "peaks = detect_peaks(norm_data, threshold=0.5, distance=10)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t[::200], norm_data, label='Normalized Downsampled Data')\n",
    "plt.plot(t[::200][peaks], norm_data[peaks], 'ro', label='Detected Peaks')\n",
    "plt.ylim(-3, 3)\n",
    "plt.title('Peak Detection in Normalized Downsampled Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>A note about namespaces</h3>\n",
    "\n",
    "<p>Each python <i>file</i> that you work with has its own isolated namespace. That means we could write `x=1` inside the module, and `x=2` inside this notebook, and the two names will <i>not</i> collide; each `x` variable lives in a different namespace. `import` statements are how we create a reference from one module's namespace into another.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import my_package.data_processing\n",
    "\n",
    "# my_package contains a namespace with the variable \"data_processing\"\n",
    "dir(my_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_processing contains its own namespace where the \"downsample\" function is defined and numpy has been imported\n",
    "dir(my_package.data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook we are working in contains its own namespace, which includes the name \"my_package\",\n",
    "# amongst others.\n",
    "dir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
