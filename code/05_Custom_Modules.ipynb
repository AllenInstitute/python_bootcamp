{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "<img src=\"support_files/images/cropped-SummerWorkshop_Header.png\">  \n",
        "<center><h1>Custom Modules and Version Control</h1></center>\n",
        "\n",
        "<p>We have seen that new functionality in Python can be encapsulated as a <i>module</i>, and that we can import modules into our own code. In this section we will create a new Python module and package. This has a few important benefits: \n",
        "\n",
        "- Encapsulating functions inside a module makes them <i>importable</i> from many locations. That means we can use the came code from multiple locations without copy/paste.\n",
        "\n",
        "- Encapsulation encourages us to make our code <i>reusable</i>. This mechanism allows us to develop tools that can be reused and shared in other projects.\n",
        "\n",
        "- We would also like to be able to <i>collaborate</i> on these tools. Encapsulation makes it easier for other people to download, modify, and share changes to our code.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Let's begin by making a simple module. For now, it will contain just one function we can use to downsample time-series data.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here is the code we'd like to include in the module:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def downsample(data, n, axis=0):\n",
        "    \"\"\"Reduce the number of samples in an array by averaging together\n",
        "    n samples at a time.\n",
        "    \"\"\"\n",
        "    if n <= 1:\n",
        "        return data\n",
        "    new_len = data.shape[axis] // n\n",
        "    s = list(data.shape)\n",
        "    s[axis] = new_len\n",
        "    s.insert(axis+1, n)\n",
        "    sl = [slice(None)] * data.ndim\n",
        "    sl[axis] = slice(0, new_len*n)\n",
        "    d1 = data[tuple(sl)]\n",
        "    d1.shape = tuple(s)\n",
        "    d2 = d1.mean(axis+1)\n",
        "    return d2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Just so we understand what this function does, let's generate a noisy time-series signal and plot it:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "t = np.linspace(0, 10, 10000)\n",
        "data = np.sin(t) + 5 * np.random.normal(size=len(t))\n",
        "plt.plot(t, data)\n",
        "plt.ylim(-20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "And this is what the same signal looks like after it has been downsampled. Note that the downsampled signal has many fewer samples, and the overall noise is much smaller.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_data = downsample(data, 200)\n",
        "plt.plot(t[::200], ds_data)\n",
        "plt.ylim(-20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Just to reiterate: We have created a useful function, and now we would like to encapsulate it into a module so that\n",
        "\n",
        "<ul>\n",
        "<li>We can re-use this function in many different places without copying it, and\n",
        "<li>We can share this function with other people.\n",
        "</ul>\n",
        "\n",
        "<br>\n",
        "<hr>\n",
        "\n",
        "Here's how to turn this code into a module:\n",
        "<ol>\n",
        "<li>Open a code editor and paste in the definition of `downsample()` given above, including the `import numpy` statement.\n",
        "<li>Save the file as `my_module.py` in the same location as this notebook.\n",
        "</ol>\n",
        "<br>\n",
        "You're done!<br>\n",
        "\n",
        "Now let's see if it works:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove the old downsample (so you can't cheat!)\n",
        "if 'downsample' in locals():\n",
        "    del downsample\n",
        "\n",
        "# Import the new definition of `downsample` from your module\n",
        "from my_module import downsample\n",
        "\n",
        "# If you get \"ImportError: No module named my_module\", then make sure\n",
        "# the .py file was saved in the same folder as this notebook file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test again:\n",
        "ds_data = downsample(data, 200)\n",
        "plt.plot(t[::200], ds_data)\n",
        "plt.ylim(-20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Good so far, but there are some issues with this approach:\n",
        "\n",
        "<ul>\n",
        "<li>As our code becomes more complex, we will often want to organize it into multiple files and make them all appear as a single importable module.\n",
        "<li>If we distribute this code, we will at least want to include a README to explain what it's about, so I'd really like my module to live inside its own folder.\n",
        "</ul>\n",
        "\n",
        "<hr>\n",
        "So now we are going to turn this module into a <i>package</i>, which is really just a collection of modules inside a folder, along with some Python glue.\n",
        "<ol>\n",
        "<li>Make a new folder, in the same location as this notebook, called `my_package`\n",
        "<li>Move `my_module.py` into this new folder\n",
        "<li>Create an empty text file called `__init__.py` inside `my_package`. (note the double underscores)\n",
        "</ol>\n",
        "<br>\n",
        "The `__init__.py` file is a hint to Python that tells it \"this folder is a package that can be imported\".\n",
        "\n",
        "<hr>\n",
        "Now let's try importing from the new package:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove the old downsample (so you can't cheat!)\n",
        "if 'downsample' in locals():\n",
        "    del downsample\n",
        "\n",
        "# Import downsample from our shiny new package\n",
        "from my_package.my_module import downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test again:\n",
        "ds_data = downsample(data, 200)\n",
        "plt.plot(t[::200], ds_data)\n",
        "plt.ylim(-20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Now that we have a package and are able to import from it, let's re-name our module to be a little more informative and  build out our package!\n",
        "<ul>\n",
        "<li>Rename `my_module.py` to `preprocessing.py`\n",
        "<li>Discuss the following methods -- which one should be in our current existing module (preprocessing.py), and which one should go in a new module? \n",
        "</ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here are the methods we'd like to include in the package\n",
        "\n",
        "# which one should we put in data_processing.py, and which belongs in its own module?\n",
        "import numpy as np\n",
        "\n",
        "def normalize(data, axis=0):\n",
        "    \"\"\"Normalize an array along a given axis to have a mean of 0 and standard deviation of 1.\"\"\"\n",
        "    mean = np.mean(data, axis=axis, keepdims=True)\n",
        "    std = np.std(data, axis=axis, keepdims=True)\n",
        "    normalized_data = (data - mean) / std\n",
        "    return normalized_data\n",
        "\n",
        "\n",
        "def detect_peaks(data, threshold, distance=1):\n",
        "    \"\"\"Detect peaks in a 1D array based on a threshold and minimum distance \n",
        "    between peaks.\n",
        "    \n",
        "    Parameters:\n",
        "    data : array-like\n",
        "        1D array of data to search for peaks.\n",
        "    threshold : float\n",
        "        Minimum value for a peak to be considered.\n",
        "    distance : int, optional\n",
        "        Minimum number of samples between consecutive peaks (default is 1).\n",
        "    \n",
        "    Returns:\n",
        "    array-like\n",
        "        Indices of the detected peaks.\n",
        "    \"\"\"\n",
        "    peaks = np.where((data[1:-1] > data[:-2]) & (data[1:-1] > data[2:]) & (data[1:-1] > threshold))[0] + 1\n",
        "    if distance > 1:\n",
        "        filtered_peaks = []\n",
        "        last_peak = -distance\n",
        "        for peak in peaks:\n",
        "            if peak - last_peak >= distance:\n",
        "                filtered_peaks.append(peak)\n",
        "                last_peak = peak\n",
        "        peaks = np.array(filtered_peaks)\n",
        "    \n",
        "    return peaks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "Hopefully we all came to the conclusion that `normalize` can be packaged with `downsample`, while `detect_peaks` belongs in its own module. \n",
        "<ul>\n",
        "<li>Similar Purpose: downsample and normalize are both data preparation methods, often used sequentially to transform raw data, so they naturally belong together in the same module.\n",
        "\n",
        "<li>Different Functionality: detect_peaks serves a distinct purpose\u2014identifying specific features (peaks) in data, which is more specialized and separate from general data transformation tasks.\n",
        "\n",
        "<li>Separation of Concerns: Grouping downsample and normalize together enhances cohesion, while placing detect_peaks in a separate module maintains modularity, making your package easier to navigate and use.\n",
        "</ul>\n",
        "\n",
        "Let's name the new module `peak_detection.py`. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from my_package.preprocessing import downsample, normalize\n",
        "from my_package.peak_detection import detect_peaks\n",
        "\n",
        "# Generating the time vector and data\n",
        "t = np.linspace(0, 10, 10000)\n",
        "data = np.sin(t) + 5 * np.random.normal(size=len(t))\n",
        "\n",
        "# Downsample and normalize the data\n",
        "ds_data = downsample(data, 200)\n",
        "norm_data = normalize(ds_data)\n",
        "\n",
        "# Detect peaks in the normalized data\n",
        "peaks = detect_peaks(norm_data, threshold=0.5, distance=10)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(t[::200], norm_data, label='Normalized Downsampled Data')\n",
        "plt.plot(t[::200][peaks], norm_data[peaks], 'ro', label='Detected Peaks')\n",
        "plt.ylim(-3, 3)\n",
        "plt.title('Peak Detection in Normalized Downsampled Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"default\" style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; color: #000;\">\n",
        "<h3>A note about namespaces</h3>\n",
        "\n",
        "<p>Each python <i>file</i> that you work with has its own isolated namespace. That means we could write `x=1` inside the module, and `x=2` inside this notebook, and the two names will <i>not</i> collide; each `x` variable lives in a different namespace. `import` statements are how we create a reference from one module's namespace into another.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import my_package.my_module\n",
        "\n",
        "# my_package contains a namespace with the variables \"preprocessing\" and \"peak_detection\"\n",
        "dir(my_package)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# my_module contains its own namespace where the \"downsample\" function is defined and numpy has been imported\n",
        "dir(my_package.preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The notebook we are working in contains its own namespace, which includes the name \"my_package\",\n",
        "# amongst others.\n",
        "dir()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}